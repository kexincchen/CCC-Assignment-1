{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiest hour: 2.0\n",
      "Happiest day: 2021-06-21\n",
      "Most active hour: 1.0\n",
      "Most active day: 2021-06-21\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON data\n",
    "with open('data/twitter-50mb.json') as f:\n",
    "    data = json.load(f)\n",
    "    tweets_df = pd.json_normalize(data['rows'])\n",
    "\n",
    "    # tweets_df = pd.DataFrame()\n",
    "    # tweets_df['created_at'] = pd.to_datetime(tweets_df['doc.data.created_at'])\n",
    "    tweets_df['doc.data.created_at'] = pd.to_datetime(tweets_df['doc.data.created_at'])\n",
    "    # tweets_df['sentiment_score'] = tweets_df['doc.data.sentiment'] \n",
    "\n",
    "    tweets_df['hour'] = tweets_df['doc.data.created_at'].dt.hour\n",
    "    tweets_df['day'] = tweets_df['doc.data.created_at'].dt.date\n",
    "\n",
    "    happiest_hour = tweets_df.groupby('hour')['doc.data.sentiment'].sum().idxmax()\n",
    "    happiest_day = tweets_df.groupby('day')['doc.data.sentiment'].sum().idxmax()\n",
    "    most_active_hour = tweets_df['hour'].value_counts().idxmax()\n",
    "    most_active_day = tweets_df['day'].value_counts().idxmax()\n",
    "\n",
    "\n",
    "    print(f\"Happiest hour: {happiest_hour}\")\n",
    "    print(f\"Happiest day: {happiest_day}\")\n",
    "    print(f\"Most active hour: {most_active_hour}\")\n",
    "    print(f\"Most active day: {most_active_day}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiest hour: 2.0\n",
      "Happiest day: 2021-06-21\n",
      "Most active hour: 1.0\n",
      "Most active day: 2021-06-21\n"
     ]
    }
   ],
   "source": [
    "df = pd.json_normalize(data['rows'])\n",
    "\n",
    "tweets_df = pd.DataFrame()\n",
    "tweets_df['created_at'] = pd.to_datetime(df['doc.data.created_at'])\n",
    "tweets_df['sentiment_score'] = df['doc.data.sentiment'] \n",
    "\n",
    "tweets_df['hour'] = tweets_df['created_at'].dt.hour\n",
    "tweets_df['day'] = tweets_df['created_at'].dt.date\n",
    "\n",
    "happiest_hour = tweets_df.groupby('hour')['sentiment_score'].sum().idxmax()\n",
    "happiest_day = tweets_df.groupby('day')['sentiment_score'].sum().idxmax()\n",
    "most_active_hour = tweets_df['hour'].value_counts().idxmax()\n",
    "most_active_day = tweets_df['day'].value_counts().idxmax()\n",
    "\n",
    "\n",
    "print(f\"Happiest hour: {happiest_hour}\")\n",
    "print(f\"Happiest day: {happiest_day}\")\n",
    "print(f\"Most active hour: {most_active_hour}\")\n",
    "print(f\"Most active day: {most_active_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiest hour: 1\n",
      "Happiest day: 2021-06-21\n",
      "Most active hour: 1\n",
      "Most active day: 2021-06-21\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for tweet in data['rows']:\n",
    "    # if 'value' not in tweet:\n",
    "    #     continue\n",
    "    if 'doc' not in tweet:\n",
    "        continue\n",
    "    if 'sentiment' not in tweet['doc']['data']:\n",
    "        continue\n",
    "    # created_at = datetime.fromisoformat(tweet['doc']['data']['created_at'])\n",
    "    created_at = parser.parse(tweet['doc']['data']['created_at'])\n",
    "    sentiment_score = tweet['doc']['data']['sentiment']\n",
    "    if isinstance(sentiment_score, dict):\n",
    "        sentiment_score = sentiment_score['score']\n",
    "    # print(sentiment_score)\n",
    "    tweets.append({'created_at': created_at, 'sentiment_score': sentiment_score})\n",
    "\n",
    "\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df['created_at'] = pd.to_datetime(df['doc.data.created_at'])\n",
    "tweets_df['sentiment_score'] = df['doc.data.sentiment'] \n",
    "\n",
    "tweets_df['hour'] = tweets_df['created_at'].dt.hour\n",
    "tweets_df['day'] = tweets_df['created_at'].dt.date\n",
    "\n",
    "happiest_hour = tweets_df.groupby('hour')['sentiment_score'].sum().idxmax()\n",
    "happiest_day = tweets_df.groupby('day')['sentiment_score'].sum().idxmax()\n",
    "most_active_hour = tweets_df['hour'].value_counts().idxmax()\n",
    "most_active_day = tweets_df['day'].value_counts().idxmax()\n",
    "\n",
    "\n",
    "print(f\"Happiest hour: {happiest_hour}\")\n",
    "print(f\"Happiest day: {happiest_day}\")\n",
    "print(f\"Most active hour: {most_active_hour}\")\n",
    "print(f\"Most active day: {most_active_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/dask/backends.py:135\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/dask/dataframe/io/json.py:251\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(url_path, orient, lines, storage_options, blocksize, sample, encoding, errors, compression, meta, engine, include_path_column, path_converter, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mread_json_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m meta \u001b[38;5;241m=\u001b[39m make_meta(meta)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/dask/dataframe/io/json.py:308\u001b[0m, in \u001b[0;36mread_json_chunk\u001b[0;34m(chunk, encoding, errors, engine, column_name, path, path_dtype, kwargs, meta)\u001b[0m\n\u001b[1;32m    307\u001b[0m s\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 308\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/io/json/_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/io/json/_json.py:973\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 973\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/io/json/_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1001\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/io/json/_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/io/json/_json.py:1347\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1347\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read the JSON data in chunks\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tweets_ddf \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/twitter-50mb.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8-sig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# # Process the data in parallel\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# tweets_ddf['created_at'] = dd.to_datetime(tweets_ddf['value.doc.data.created_at'])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# tweets_ddf['sentiment_score'] = tweets_ddf['value.doc.data.sentiment']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(f\"Most active hour: {most_active_hour}\")\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# print(f\"Most active day: {most_active_day}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/site-packages/dask/backends.py:137\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod registered to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: Expected object or value"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Read the JSON data in chunks\n",
    "tweets_ddf = dd.read_json('data/twitter-50mb.json', \n",
    "                          encoding = 'utf-8-sig',\n",
    "                          blocksize=64 * (1024 ** 2))\n",
    "\n",
    "# # Process the data in parallel\n",
    "# tweets_ddf['created_at'] = dd.to_datetime(tweets_ddf['value.doc.data.created_at'])\n",
    "# tweets_ddf['sentiment_score'] = tweets_ddf['value.doc.data.sentiment']\n",
    "# tweets_ddf['hour'] = tweets_ddf['created_at'].dt.hour\n",
    "# tweets_ddf['day'] = tweets_ddf['created_at'].dt.date\n",
    "\n",
    "# # Calculate the required metrics in parallel\n",
    "# happiest_hour = tweets_ddf.groupby('hour')['sentiment_score'].mean().nlargest(1).idxmax().compute()\n",
    "# happiest_day = tweets_ddf.groupby('day')['sentiment_score'].mean().nlargest(1).idxmax().compute()\n",
    "# most_active_hour = tweets_ddf['hour'].value_counts().idxmax().compute()\n",
    "# most_active_day = tweets_ddf['day'].value_counts().idxmax().compute()\n",
    "\n",
    "# print(f\"Happiest hour: {happiest_hour}\")\n",
    "# print(f\"Happiest day: {happiest_day}\")\n",
    "# print(f\"Most active hour: {most_active_hour}\")\n",
    "# print(f\"Most active day: {most_active_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>offset</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406813874750300166', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406814402272137216', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406920780328312832', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406929052724654084', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406932228165099530', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406801815958528009', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406800773623672833', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406807450959843328', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{'id': '1406810512587771905', 'key': [2021, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>185875709</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_rows  offset                                               rows\n",
       "0       185875709       0  {'id': '1406813874750300166', 'key': [2021, 6,...\n",
       "1       185875709       0  {'id': '1406814402272137216', 'key': [2021, 6,...\n",
       "2       185875709       0  {'id': '1406920780328312832', 'key': [2021, 6,...\n",
       "3       185875709       0  {'id': '1406929052724654084', 'key': [2021, 6,...\n",
       "4       185875709       0  {'id': '1406932228165099530', 'key': [2021, 6,...\n",
       "...           ...     ...                                                ...\n",
       "49995   185875709       0  {'id': '1406801815958528009', 'key': [2021, 6,...\n",
       "49996   185875709       0  {'id': '1406800773623672833', 'key': [2021, 6,...\n",
       "49997   185875709       0  {'id': '1406807450959843328', 'key': [2021, 6,...\n",
       "49998   185875709       0  {'id': '1406810512587771905', 'key': [2021, 6,...\n",
       "49999   185875709       0                                                 {}\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('data/twitter-50mb.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
